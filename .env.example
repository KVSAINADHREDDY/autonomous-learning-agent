# =========================================================
# AUTONOMOUS LEARNING AGENT - CONFIGURATION
# =========================================================

# ---------------------------------------------------------
# LLM Provider Configuration
# ---------------------------------------------------------
# Options: huggingface, groq, openai, azure, github
MODEL_PROVIDER=huggingface

# Hugging Face (FREE - Recommended for this project)
# Get your token from: https://huggingface.co/settings/tokens
HUGGINGFACE_API_KEY=your_huggingface_token_here

# Groq (FREE Tier - Fast inference)
# Get API key from: https://console.groq.com
GROQ_API_KEY=your_groq_api_key_here

# GitHub Models (FREE Tier - Alternative)
# Get token from: https://github.com/settings/tokens
GITHUB_TOKEN=your_github_token_here

# OpenAI (Paid)
# OPENAI_API_KEY=your_openai_api_key_here

# ---------------------------------------------------------
# Search API Configuration
# ---------------------------------------------------------
# Tavily API (100 free searches/month)
# Get API key from: https://tavily.com
TAVILY_API_KEY=your_tavily_api_key_here

# SerpAPI (Fallback)
# SERP_API_KEY=your_serp_api_key_here

# ---------------------------------------------------------
# LangSmith Observability (Optional but recommended)
# ---------------------------------------------------------
# Get API key from: https://smith.langchain.com
LANGSMITH_API_KEY=your_langsmith_api_key_here
LANGSMITH_PROJECT=autonomous-learning-agent
LANGCHAIN_TRACING_V2=false

# ---------------------------------------------------------
# Learning Configuration
# ---------------------------------------------------------
# Pass threshold for checkpoints (70% = 0.70)
UNDERSTANDING_THRESHOLD=0.70

# Maximum retry attempts for quizzes
MAX_RETRIES=3

# Number of questions per quiz
QUESTIONS_PER_QUIZ=5

# Vector store chunk size
CHUNK_SIZE=500
CHUNK_OVERLAP=100

# ---------------------------------------------------------
# Embedding Model Configuration
# ---------------------------------------------------------
# Sentence Transformer model for embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2